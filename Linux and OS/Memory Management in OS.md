**Memory Management in OS**

The memory can be defined as a collection of objects or data in a specific format. This is used to store the data and instructions for the execution of the program or process the data. The main motive of the computer system is to execute the programs, at the same time it is also required to store all the data in memory which is required at the time for the execution. Here the CPU gets the instructions from the memory according to the value of the program counter. For doing all these complex as well as multi-programming things memory management is important.

*Main Memory*

Main memory is the main hub for all the processes and executions happening inside of a system. Memory management can also be reffered as large array of words or bytes, ranging in size from thousands to billions of data chunks. Main memory is a repository of frequent information shared by the CPU while doing operations like compute, I/O management, etc. Main memory is used to store the data which is associated with the process running on the CPU so moving instructions and data between the main memory and the CPU is very fast.

*Memory Management*

Memory management can be more of defined as the process of controlling and coordinating a computers main memory. So this ensures that blocks of memory space are managed properly and efficiently used by the OS, applications, and other running processes, In the same process it also used to keep the eye on memory which is being utilized by the processors. As part of this whole process Memory management it takes controls of the operations like allocation of memory, de-allocation of memory, and also the protection of memory. Memory management is also responsible for the management of the virtual memory. Memory Management also plays a crucial role in optimizing the memory usage which is reponsible for getting the best performance out of the system. Memory management also helps in maintaining the security and data integrity while execution is in the process.

*Physical and Logical Address*

- *Physical Address:* The address which can be seen and identified by the memory unit or the address which is being allocated to the memory address registers is called as physical address. Physical address can also be termed as real addresses. This physical address is computed by the MMU (Memory Management Unit) and is used to access the memory location. The physical address always remains the constant and is not changing during the execution of the program.

- *Logical Address:* The addresses which can be generated by the CPU is known as the "Logical Address", which is also being called as virtual addresses. Logical address can be changed or edited as per their requirement.

*Static and Dynamic Loading*

For loading a process into the main memory, loader is used. There are two types of loaders available:

- *Static Loading:* Static loading is basically used in loading of the entire program into a fixed addresses, which requires more memory space.

- *Dynamic Loading:* In Dynamic loading the whole program and all the data required for the execution of the program must be in the memory. It is used in the condition to gain proper utilization of the memory space. One of the biggest advantages of the dynamic loading is that the unused routine is not loaded. In dynamic loading, a routine is not loaded until it is required and called by the program. This is also known as lazy loading. This mode of loading is useful in case when a large amount of code needed to handle a particular task is not required for the execution of the program, which makes it more efficient.

*Static and Dynamic Linking*

To perform the tasks which are linked to each other, the linker is used. The linker is a kind of program which takes one or more object files which are generated by the compiler and combines them to make a single executable file.

- *Static Linking:* Static linking is the process in which, the linker combines all the required program modules into a single executable file. This helps in the way, by not bringing any runtime dependency at the time when the execution starts.

- *Dynamic Linking:* In Dynamic Linking, a small piece of code also known as "Stub" is included for every appropriate library routine reference. Whenever this "Stub" is executed it checks for the necessary routines in the memory as are they present or not. If it founds, the routine is missing, it loads the routine to the memory.

*Swapping in Memory*

Whenever the process is executed, it should reside inside the main memory. In Swapping the process is which is currently residing in the main memory is shifted into the secondary memory which is comparatively faster than the main memory. This process of swapping gives more space to the main memory for the execution of the other process. The main part of the swapping is transfered time which is required to transfer the process from the main memory or to the secondary memory. Swapping is also called as roll-out or roll because if a task with a high priority is to be executed, the task with a low priority is swapped out of the memory and the task with a high priority is swapped in the memory. After the execution of the task with a high priority, the task with a low priority is swapped back into the memory.

*Partition Table*

Once partitions are defined, the operating system must keep track of the memory partitions, which is done using a data structure called as partition table. The partition table is a table which contains the information about the partitions. You can say Partition table as a map for the memory. The partition table contains the information about the size of the partition, the starting address of the partition, the ending address of the partition, the status of the partition, and the name of the partition.

*Contiguous Memory Allocation*

The main memory should accept both the operating system and the client processes. That's why memory allocation is an important part of the operating system. The memory allocation usually divides the main memory into two parts, one is for the operating system and the other is for the client processes. We usually need our memory to handle multiple processes at the same time. Due to which we need to allocate the available memory to the processes, which are in the input queue and ready to be processed. As per the adjacent memory allotment, the memory is divided into the fixed size partitions and processes are allocated in the memory sharing each others border partitions. The main advantage of this method is that it is easy to implement and it is also easy to manage.

*Non-Contiguous Memory Allocation*

In non-contiguous memory allocation, every process is allocated a series of non-contiguous memory blocks, which can be located anywhere in the memory. Non-Contiguous memory allocation requires pointers to link the blocks of the non-contiguous memory together. These pointers are so useful at the time of the execution of the process as they help in locating the memory blocks during the execution of the process. The main advantage of this method is that memory blocks can be allocated in the memory as per the current requirement of the process, instead of allocating the memory in the fixed size partitions and then allocating the memory to the process. There is one more exciting advantage of this method, which is regarding the flexible and effective memory allocation, which makes it more efficient and available to allocate the memory to the process whenever free memory is available.

*Memory Allocation*

Memory allocation is similar to using our room or apartment in a very efficient way. Since when its about memory with limited space it is needed to be used in efficient manner. One of the easiest method for memory allocation, is to divide the memory into fixed size partitions and then allocating the memory to exactly one process.

- *Multiple Partition Allocation:* In this process, a process is selected from the input queue and is allocated to a free partition. As the process terminates, the partition is freed and is made available for the next process.

- *Fixed Partition Allocation:* In this method of allocation, the operating system is responsible for maintaing a table that indicates the status of each partition, like whether it is free or occupied by the processes. At starting, all the partitions are free and are available for the processes. This available memory is known as "Hole". Whenever the process arrives and requests for the memory allocation, the operating system searches for "Hole" or free space which is large enough to accommodate the process. If the Hole is found the process is allocated to the memory for further processing and as the work gets completed the process is removed from the memory and the memory is made available for the next process, which will be useful for further processing.
While allocating the memory sometimes the dynamic allocation problem occurs, which concerns how to satisfy the request of the size n from the list of free holes, There are some solutions to this problem: