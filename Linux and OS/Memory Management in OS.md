**Memory Management in OS**

The memory can be defined as a collection of objects or data in a specific format. This is used to store the data and instructions for the execution of the program or process the data. The main motive of the computer system is to execute the programs, at the same time it is also required to store all the data in memory which is required at the time for the execution. Here the CPU gets the instructions from the memory according to the value of the program counter. For doing all these complex as well as multi-programming things memory management is important.

*Main Memory*

Main memory is the main hub for all the processes and executions happening inside of a system. Memory management can also be reffered as large array of words or bytes, ranging in size from thousands to billions of data chunks. Main memory is a repository of frequent information shared by the CPU while doing operations like compute, I/O management, etc. Main memory is used to store the data which is associated with the process running on the CPU so moving instructions and data between the main memory and the CPU is very fast.

*Memory Management*

Memory management can be more of defined as the process of controlling and coordinating a computers main memory. So this ensures that blocks of memory space are managed properly and efficiently used by the OS, applications, and other running processes, In the same process it also used to keep the eye on memory which is being utilized by the processors. As part of this whole process Memory management it takes controls of the operations like allocation of memory, de-allocation of memory, and also the protection of memory. Memory management is also responsible for the management of the virtual memory. Memory Management also plays a crucial role in optimizing the memory usage which is reponsible for getting the best performance out of the system. Memory management also helps in maintaining the security and data integrity while execution is in the process.

*Physical and Logical Address*

- *Physical Address:* The address which can be seen and identified by the memory unit or the address which is being allocated to the memory address registers is called as physical address. Physical address can also be termed as real addresses. This physical address is computed by the MMU (Memory Management Unit) and is used to access the memory location. The physical address always remains the constant and is not changing during the execution of the program.

- *Logical Address:* The addresses which can be generated by the CPU is known as the "Logical Address", which is also being called as virtual addresses. Logical address can be changed or edited as per their requirement.

*Static and Dynamic Loading*

For loading a process into the main memory, loader is used. There are two types of loaders available:

- *Static Loading:* Static loading is basically used in loading of the entire program into a fixed addresses, which requires more memory space.

- *Dynamic Loading:* In Dynamic loading the whole program and all the data required for the execution of the program must be in the memory. It is used in the condition to gain proper utilization of the memory space. One of the biggest advantages of the dynamic loading is that the unused routine is not loaded. In dynamic loading, a routine is not loaded until it is required and called by the program. This is also known as lazy loading. This mode of loading is useful in case when a large amount of code needed to handle a particular task is not required for the execution of the program, which makes it more efficient.

*Static and Dynamic Linking*

To perform the tasks which are linked to each other, the linker is used. The linker is a kind of program which takes one or more object files which are generated by the compiler and combines them to make a single executable file.

- *Static Linking:* Static linking is the process in which, the linker combines all the required program modules into a single executable file. This helps in the way, by not bringing any runtime dependency at the time when the execution starts.

- *Dynamic Linking:* In Dynamic Linking, a small piece of code also known as "Stub" is included for every appropriate library routine reference. Whenever this "Stub" is executed it checks for the necessary routines in the memory as are they present or not. If it founds, the routine is missing, it loads the routine to the memory.

*Swapping in Memory*

Whenever the process is executed, it should reside inside the main memory. In Swapping the process is which is currently residing in the main memory is shifted into the secondary memory which is comparatively faster than the main memory. This process of swapping gives more space to the main memory for the execution of the other process. The main part of the swapping is transfered time which is required to transfer the process from the main memory or to the secondary memory. Swapping is also called as roll-out or roll because if a task with a high priority is to be executed, the task with a low priority is swapped out of the memory and the task with a high priority is swapped in the memory. After the execution of the task with a high priority, the task with a low priority is swapped back into the memory.

*Partition Table*

Once partitions are defined, the operating system must keep track of the memory partitions, which is done using a data structure called as partition table. The partition table is a table which contains the information about the partitions. You can say Partition table as a map for the memory. The partition table contains the information about the size of the partition, the starting address of the partition, the ending address of the partition, the status of the partition, and the name of the partition.

*Contiguous Memory Allocation*

The main memory should accept both the operating system and the client processes. That's why memory allocation is an important part of the operating system. The memory allocation usually divides the main memory into two parts, one is for the operating system and the other is for the client processes. We usually need our memory to handle multiple processes at the same time. Due to which we need to allocate the available memory to the processes, which are in the input queue and ready to be processed. As per the adjacent memory allotment, the memory is divided into the fixed size partitions and processes are allocated in the memory sharing each others border partitions. The main advantage of this method is that it is easy to implement and it is also easy to manage.

*Non-Contiguous Memory Allocation*

In non-contiguous memory allocation, every process is allocated a series of non-contiguous memory blocks, which can be located anywhere in the memory. Non-Contiguous memory allocation requires pointers to link the blocks of the non-contiguous memory together. These pointers are so useful at the time of the execution of the process as they help in locating the memory blocks during the execution of the process. The main advantage of this method is that memory blocks can be allocated in the memory as per the current requirement of the process, instead of allocating the memory in the fixed size partitions and then allocating the memory to the process. There is one more exciting advantage of this method, which is regarding the flexible and effective memory allocation, which makes it more efficient and available to allocate the memory to the process whenever free memory is available.

*Memory Allocation*

Memory allocation is similar to using our room or apartment in a very efficient way. Since when its about memory with limited space it is needed to be used in efficient manner. One of the easiest method for memory allocation, is to divide the memory into fixed size partitions and then allocating the memory to exactly one process.

- *Multiple Partition Allocation:* In this process, a process is selected from the input queue and is allocated to a free partition. As the process terminates, the partition is freed and is made available for the next process.

- *Fixed Partition Allocation:* In this method of allocation, the operating system is responsible for maintaing a table that indicates the status of each partition, like whether it is free or occupied by the processes. At starting, all the partitions are free and are available for the processes. This available memory is known as "Hole". Whenever the process arrives and requests for the memory allocation, the operating system searches for "Hole" or free space which is large enough to accommodate the process. If the Hole is found the process is allocated to the memory for further processing and as the work gets completed the process is removed from the memory and the memory is made available for the next process, which will be useful for further processing.
While allocating the memory sometimes the dynamic allocation problem occurs, which concerns how to satisfy the request of the size n from the list of free holes, There are ways to fix this issue, which are:

*First Fit:* This process works like, whenever the process arrives and requests for the memory allocation, the operating system searches for the hole(A hole can be reffered to as the free space with the available memory to allocate to the process) which is large enough to accommodate the process. If the hole is found and process is being allocated to the memory for further processing. If the hole is not found, the process is kept in the waiting queue until the hole is found. For example, if the process is requesting for the memory of size 100 and the hole is of size 200, then the process is allocated to the memory and the remaining 100 is left as a hole.

*Best Fit:* In this process, the operating system arranges the holes in the ascending order of their sizes and then searches for the size closest to the size of the process. If the hole is found and the process is allocated to the memory for further processing. If the hole is not found, the process is kept in the waiting queue until the hole is found. For example, if the process is request    ing for the memory of size 100 and if it founds the hole of size 100 then the process is allocated to the memory.

*Worst Fit:* In this process, the operating system arranges the holes in the descending order of their sizes and then searches for the largest available hole and assigns the value to it. If the hole is found and the process is allocated to the memory for further processing. This method produces the largest leftover hole. For example, if the process of size 15 is allocated to the hole of size 100, then the remaining 85 is left as a hole. Which is considered as the inefficient use of the memory as the hole of size 85 is left as a hole.

*Paging*

Paging is a memory management technique which is used to end the need for the contiguous allocation of the physical memory. This process allows the physical address space of the process to be non-contiguous.

- Logical Address or Virtual Address (Represented in the form of bits): An address generated by the CPU.

- Logical Address Space or Virtual Address Space (Represented in the form of words or bytes): This is set of all the logical addresses generated by a program.

- Physical Address (Represented in the form of bits): An address actually available on a memory unit.

- Physical Address Space (Represented in the form of words or bytes): This is the set of all the physical addresses corresponding to the logical addresses.

Examples:

- If logical address = 31 bits, then logical address space = 2^31 words or 2 G words.

- If logical address space = 128 M words = 2^7*2^20 words = 2^27 words = then logical address = log2(2^27) = 27 bits.

- If physical address = 22 bits, then physical address space = 2^22 words = 4 M words. (1 M = 2^20)

- If physical address space = 16 M words = 2^4*2^20 words, then physical address = log2(2^24) = 24 bits.

The mapping of the logical address to the physical address is done mostly by the Memory Management Unit (MMU) which is a hardware device and with this mapping is called as Paging Technique.

- The physical address spaces is conceptually divided in the several equal sized blocks called as frames.

- The logical address space is logically divided into equal sized blocks called as pages.

- Here the size of the page is equal to the size of the frame i.e, Page Size = Frame Size.

*Fragmentation*

Fragmentation can be considered as the time when the process is loaded into the memory and removed after the execution from the memory, Which creates a small free holes. These empty spaces or holes can't be assigned any further process as they are too small to be assigned to any of the new process waiting in the queue. To reduce the wastage of the memory or fragmentation problems and the degree of multi-programming.

- Internal Fragmentation: This happens when the memory blocks are allocated to make the process more than the requested size. Because of this, in this process more space is left over and creating an internal fragmentation problem. For example, if the processs has a fixed partitioning used for memory allocation and with the different size of blocks, with 3MB, 6MB and 9MB space. Now a process p5 of size 2MB comes for allocation, then it will be allocated to the block of 3MB, which will leave 1MB as waste and this can't be used for any other process.

- External Fragmentation: In this situation, we have a free memory block, but we can't use it for the process as it is not contiguous. For example, Consider three processes P1, P2, and P3 of size 5MB, 6MB, and 8MB respectively. Now, we will see the memory blocks of size 6MB, 8MB and 10MB, but after allocating the processes, we have 1MB, 2MB and 2MB of free space left, which can't be assigned as the free memory is not contiguous. This is called external fragmentation.

The addresses generated by the CPU is divided into two parts:

- Page Number (p): This is the number of bits which is required to represent the pages in Logical Address Space or the page number.

- Page Offset (d): The Number of bits required to represent the particular word in the page or the page size of Logical Address Space or the word number of a page or the page offset.

As the Physical address is divided into two parts:

- Frame Number (p): This is the required number of the bits to represent the frames of Physical Address Space or the frame number.

- Frame Offset (d): This is the required number of the bits to represent the particular word in the frame or the frame size of Physical Address Space or the word number of a frame or frame offset.

The hardware implementation of the paging table can be done using dedicated hardware or using dedicated registers. But the use of the registers for the page table is satisfactory only if the page table is small in size. If the page table is large in size, with large number of entries then we can use the TLB (Translation Look-aside Buffer), a special, small, fast look-up hardware cache.

- The TLB is an associative memory which has higher speeds.

- Each entry in the TLB consists of two parts: a tag and a value.

- When this memory is being used, then an item is being compared with all the tags simultaneously. If the tag is found, then the corresponding value is returned.

```
Let the,

Memory Access Time = m

If the page table are kept in the main memory,

Effective Access Time = m(for page table) + m(for particular page in page table)
```
